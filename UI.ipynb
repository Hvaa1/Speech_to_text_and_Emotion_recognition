{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "authorship_tag": "ABX9TyPmcxJaH1Hab/2KLHMLMc8T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hvaa1/Speech_to_text_and_Emotion_recognition/blob/main/UI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8v5lnZUYY14f",
        "outputId": "854f8518-f396-4d1e-ac70-256b2f794f16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd \"/content/drive/MyDrive/ColabNotebooks/BTL_NLP/WhisperFT\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Vcf8rymZBp9",
        "outputId": "604ceb89-eac5-450d-a3e3-1af352849c18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ColabNotebooks/BTL_NLP/WhisperFT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fastapi uvicorn pyngrok transformers torchaudio soundfile peft accelerate\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_VxTrGQZPUc",
        "outputId": "5849cd90-6f96-47b1-d9e9-69be7df57ca2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.12/dist-packages (0.118.3)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.12/dist-packages (0.38.0)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.5.0-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.3)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.12/dist-packages (0.13.1)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.12/dist-packages (0.18.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: starlette<0.49.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi) (0.48.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from fastapi) (2.12.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from fastapi) (4.15.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn) (8.3.1)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.12/dist-packages (from uvicorn) (0.16.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: torch==2.9.0 in /usr/local/lib/python3.12/dist-packages (from torchaudio) (2.9.0+cu126)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchaudio) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile) (2.0.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile) (2.23)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.4.2)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.12/dist-packages (from starlette<0.49.0,>=0.40.0->fastapi) (4.12.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch==2.9.0->torchaudio) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.9.0->torchaudio) (3.0.3)\n",
            "Downloading pyngrok-7.5.0-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "from fastapi import FastAPI, UploadFile, File, WebSocket, Request\n",
        "from fastapi.responses import HTMLResponse\n",
        "from fastapi.templating import Jinja2Templates\n",
        "from transformers import (\n",
        "    WhisperForConditionalGeneration,\n",
        "    WhisperProcessor,\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification\n",
        ")\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchaudio\n",
        "import io\n",
        "import numpy as np\n",
        "\n",
        "# ================= INIT =================\n",
        "app = FastAPI(title=\"Nhận diện cảm xúc qua giọng nói\")\n",
        "templates = Jinja2Templates(directory=\"templates\")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ===== WHISPER =====\n",
        "WHISPER_DIR = \"/content/drive/MyDrive/ColabNotebooks/BTL_NLP/WhisperFT/whisper_merged\"\n",
        "whisper_processor = WhisperProcessor.from_pretrained(WHISPER_DIR)\n",
        "whisper_model = WhisperForConditionalGeneration.from_pretrained(WHISPER_DIR)\n",
        "whisper_model.to(device)\n",
        "whisper_model.eval()\n",
        "\n",
        "# ===== PHOBERT =====\n",
        "PHOBERT_DIR = \"/content/drive/MyDrive/ColabNotebooks/BTL_NLP/EmotionRecognition/Phobert_ft1\"\n",
        "phobert_tokenizer = AutoTokenizer.from_pretrained(PHOBERT_DIR)\n",
        "phobert_model = AutoModelForSequenceClassification.from_pretrained(PHOBERT_DIR)\n",
        "phobert_model.to(device)\n",
        "phobert_model.eval()\n",
        "\n",
        "labels_map_vi = {\n",
        "    0: \"Giận dữ\",\n",
        "    1: \"Ghê tởm\",\n",
        "    2: \"Sợ hãi\",\n",
        "    3: \"Vui vẻ\",\n",
        "    4: \"Buồn bã\",\n",
        "    5: \"Ngạc nhiên\",\n",
        "    6: \"Khác\"\n",
        "}\n",
        "\n",
        "# ================= UTILS =================\n",
        "def whisper_transcribe(waveform, sr):\n",
        "    if sr != 16000:\n",
        "        waveform = torchaudio.functional.resample(waveform, sr, 16000)\n",
        "\n",
        "    if waveform.ndim > 1:\n",
        "        waveform = waveform.mean(dim=0, keepdim=True)\n",
        "\n",
        "    waveform = waveform.squeeze().numpy()\n",
        "\n",
        "    inputs = whisper_processor.feature_extractor(\n",
        "        waveform,\n",
        "        sampling_rate=16000,\n",
        "        return_tensors=\"pt\"\n",
        "    ).input_features.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        ids = whisper_model.generate(\n",
        "          inputs,\n",
        "          max_length=225,\n",
        "          no_repeat_ngram_size=3,\n",
        "          repetition_penalty=1.2,\n",
        "          length_penalty=1.0,\n",
        "          early_stopping=True\n",
        "        )\n",
        "\n",
        "    return whisper_processor.tokenizer.decode(\n",
        "        ids[0],\n",
        "        skip_special_tokens=True\n",
        "    ).strip().lower()\n",
        "\n",
        "\n",
        "def predict_emotion(text):\n",
        "    if len(text.split()) < 2:\n",
        "        return \"Khác\", 1.0\n",
        "\n",
        "    enc = phobert_tokenizer(\n",
        "        text,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        padding=True,\n",
        "        max_length=128\n",
        "    )\n",
        "    enc = {k: v.to(device) for k, v in enc.items()}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits = phobert_model(**enc).logits\n",
        "\n",
        "    probs = F.softmax(logits, dim=-1)\n",
        "    conf, pred = torch.max(probs, dim=-1)\n",
        "\n",
        "    return labels_map_vi[pred.item()], float(conf.item())\n",
        "\n",
        "\n",
        "# ================= ROUTES =================\n",
        "@app.get(\"/\", response_class=HTMLResponse)\n",
        "def home(request: Request):\n",
        "    return templates.TemplateResponse(\"index.html\", {\"request\": request})\n",
        "\n",
        "\n",
        "@app.post(\"/analyze\")\n",
        "async def analyze_audio(file: UploadFile = File(...)):\n",
        "    audio_bytes = await file.read()\n",
        "    waveform, sr = torchaudio.load(io.BytesIO(audio_bytes))\n",
        "\n",
        "    text = whisper_transcribe(waveform, sr)\n",
        "    emotion, confidence = predict_emotion(text)\n",
        "\n",
        "    return {\n",
        "        \"text\": text,\n",
        "        \"emotion\": emotion,\n",
        "        \"confidence\": confidence\n",
        "    }\n",
        "\n",
        "\n",
        "@app.websocket(\"/ws/stream\")\n",
        "async def websocket_stream(ws: WebSocket):\n",
        "    await ws.accept()\n",
        "    audio_buffer = []\n",
        "\n",
        "    try:\n",
        "        while True:\n",
        "            data = await ws.receive_bytes()\n",
        "            chunk = np.frombuffer(data, dtype=np.float32)\n",
        "            audio_buffer.append(chunk)\n",
        "\n",
        "            if sum(len(x) for x in audio_buffer) >= 16000 * 2:\n",
        "                waveform = np.concatenate(audio_buffer)\n",
        "                audio_buffer = []\n",
        "\n",
        "                inputs = whisper_processor.feature_extractor(\n",
        "                    waveform,\n",
        "                    sampling_rate=16000,\n",
        "                    return_tensors=\"pt\"\n",
        "                ).input_features.to(device)\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    ids = whisper_model.generate(inputs, max_length=225)\n",
        "\n",
        "                text = whisper_processor.tokenizer.decode(\n",
        "                    ids[0],\n",
        "                    skip_special_tokens=True\n",
        "                ).strip().lower()\n",
        "\n",
        "                emotion, conf = predict_emotion(text)\n",
        "\n",
        "                await ws.send_json({\n",
        "                    \"text\": text,\n",
        "                    \"emotion\": emotion,\n",
        "                    \"confidence\": conf\n",
        "                })\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"WebSocket closed:\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-p4lpbMZT7S",
        "outputId": "a3681aa3-502f-4f69-e7fb-a100b3ebb952"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Chạy uvicorn ở chế độ background thực sự, log sẽ được ghi vào server.log thay vì in ra màn hình\n",
        "!nohup uvicorn app:app --host 0.0.0.0 --port 8000 > server.log 2>&1 &\n",
        "print(\"Server đang chạy ngầm. Bạn có thể chạy cell tiếp theo.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSgMv5JmZnkM",
        "outputId": "bd441a4d-4550-4976-fd54-09ff53d18eb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Server đang chạy ngầm. Bạn có thể chạy cell tiếp theo.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok config add-authtoken 36u7hrCwA1WKNLFmgyBzVhQmYFP_5sYRAKVWnAbPBFcKzzA29\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LA7bLqfgcIyC",
        "outputId": "ac3ff60e-a454-44c3-bd28-f0e983087742"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "public_url = ngrok.connect(8000)\n",
        "print(public_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHpbfsJ4aLRL",
        "outputId": "dc322aa7-4e7e-4755-d70d-14196dafc300"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NgrokTunnel: \"https://42cd12b33517.ngrok-free.app\" -> \"http://localhost:8000\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchcodec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPZlxX4ldW58",
        "outputId": "7b5fa235-d008-41c2-fc24-495ed5a46608"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchcodec\n",
            "  Downloading torchcodec-0.9.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (11 kB)\n",
            "Downloading torchcodec-0.9.1-cp312-cp312-manylinux_2_28_x86_64.whl (2.1 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m82.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torchcodec\n",
            "Successfully installed torchcodec-0.9.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CUZ-fXXAjl1d"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}